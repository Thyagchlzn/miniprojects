{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import MaxPooling2D, AveragePooling2D\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from tensorflow.keras.layers import Lambda, Flatten, Dense\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras import backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import PIL\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#naive  face verification\n",
    "from tensorflow.keras.models import model_from_json\n",
    "\n",
    "json_file = open('keras-facenet-h5/model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(loaded_model_json)\n",
    "model.load_weights('keras-facenet-h5/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.inputs)\n",
    "print(model.outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f05732f7068382cb",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#triplet_loss\n",
    "\n",
    "def triplet_loss(y_true, y_pred, alpha = 0.2):\n",
    "    \n",
    "    \n",
    "    anchor, positive, negative = y_pred[0], y_pred[1], y_pred[2]\n",
    "    \n",
    "    anchor, positive, negative = y_pred[0], y_pred[1], y_pred[2]\n",
    "    pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor,positive)),axis=-1)\n",
    "    neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor,negative)),axis=-1)\n",
    "    basic_loss = tf.maximum(tf.add(tf.subtract(pos_dist,neg_dist),alpha),0)\n",
    "    loss = tf.reduce_sum(basic_loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-953bcab8e9bbba10",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "FRmodel = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.keras.backend.set_image_data_format('channels_last')\n",
    "def img_to_encoding(image_path, model):\n",
    "    img = tf.keras.preprocessing.image.load_img(image_path, target_size=(160, 160))\n",
    "    img = np.around(np.array(img) / 255.0, decimals=12)\n",
    "    x_train = np.expand_dims(img, axis=0)\n",
    "    embedding = model.predict_on_batch(x_train)\n",
    "    return embedding / np.linalg.norm(embedding, ord=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = {}\n",
    "database[\"danielle\"] = img_to_encoding(\"images/danielle.png\", FRmodel)\n",
    "database[\"younes\"] = img_to_encoding(\"images/younes.jpg\", FRmodel)\n",
    "database[\"tian\"] = img_to_encoding(\"images/tian.jpg\", FRmodel)\n",
    "database[\"andrew\"] = img_to_encoding(\"images/andrew.jpg\", FRmodel)\n",
    "database[\"kian\"] = img_to_encoding(\"images/kian.jpg\", FRmodel)\n",
    "database[\"dan\"] = img_to_encoding(\"images/dan.jpg\", FRmodel)\n",
    "database[\"sebastiano\"] = img_to_encoding(\"images/sebastiano.jpg\", FRmodel)\n",
    "database[\"bertrand\"] = img_to_encoding(\"images/bertrand.jpg\", FRmodel)\n",
    "database[\"kevin\"] = img_to_encoding(\"images/kevin.jpg\", FRmodel)\n",
    "database[\"felix\"] = img_to_encoding(\"images/felix.jpg\", FRmodel)\n",
    "database[\"benoit\"] = img_to_encoding(\"images/benoit.jpg\", FRmodel)\n",
    "database[\"arnaud\"] = img_to_encoding(\"images/arnaud.jpg\", FRmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "danielle = tf.keras.preprocessing.image.load_img(\"images/messi.png\", target_size=(160, 160))\n",
    "kian = tf.keras.preprocessing.image.load_img(\"images/neymar.jpg\", target_size=(160, 160))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.around(np.array(kian) / 255.0, decimals=12).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.around(np.array(danielle) / 255.0, decimals=12).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ba2f317e79e15a2f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def verify(image_path, identity, database, model):\n",
    "    \n",
    "    encoding = img_to_encoding(image_path,model)\n",
    "    dist = np.linalg.norm(encoding - database[identity])\n",
    "    if dist < 0.7:\n",
    "        print(\"It's \" + str(identity) + \", welcome in!\")\n",
    "        door_open = True\n",
    "    else:\n",
    "        print(\"It's not \" + str(identity) + \", please go away\")\n",
    "        door_open = False\n",
    " \n",
    "    return dist, door_open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a04ff2b5fd1186f8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def who_is_it(image_path, database, model):\n",
    "    encoding = img_to_encoding(image_path,model)\n",
    "    min_dist = 100\n",
    "    for (name, db_enc) in database.items():\n",
    "        dist = np.linalg.norm(encoding - db_enc)\n",
    "\n",
    "        # If this distance is less than the min_dist, then set min_dist to dist, and identity to name. (â‰ˆ 3 lines)\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            identity = name\n",
    "   \n",
    "    if min_dist > 0.7:\n",
    "        print(\"Not in the database.\")\n",
    "    else:\n",
    "        print (\"it's \" + str(identity) + \", the distance is \" + str(min_dist))\n",
    "        \n",
    "    return min_dist, identity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
